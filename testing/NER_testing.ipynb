{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with focus on locations\n",
    "\n",
    "packages to test\n",
    "- nltk\n",
    "- spaCy\n",
    "- neuralcoref (maybe, built on spaCy so maybe not worth it)\n",
    "\n",
    "For `nltk` and `spaCy`, starting with this nice post using both: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "start with post's examples to make sure it all works as advertised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/clayton/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# not in post, but trying to run `word_tokenize` told me to run this:\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# as well as this:\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = word_tokenize(sent)\n",
    "    sent = pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('fined', 'VBD'),\n",
       " ('Google', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('$', '$'),\n",
       " ('5.1', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('abusing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mobile', 'JJ'),\n",
       " ('phone', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('alter', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('practices', 'NNS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  European/JJ\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  Google/NNP\n",
      "  (NP a/DT record/NN)\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  (NP power/NN)\n",
      "  in/IN\n",
      "  (NP the/DT mobile/JJ phone/NN)\n",
      "  (NP market/NN)\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (NP the/DT company/NN)\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'JJ', 'O'),\n",
      " ('authorities', 'NNS', 'O'),\n",
      " ('fined', 'VBD', 'O'),\n",
      " ('Google', 'NNP', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('record', 'NN', 'I-NP'),\n",
      " ('$', '$', 'O'),\n",
      " ('5.1', 'CD', 'O'),\n",
      " ('billion', 'CD', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Wednesday', 'NNP', 'O'),\n",
      " ('for', 'IN', 'O'),\n",
      " ('abusing', 'VBG', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('power', 'NN', 'B-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('mobile', 'JJ', 'I-NP'),\n",
      " ('phone', 'NN', 'I-NP'),\n",
      " ('market', 'NN', 'B-NP'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('ordered', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('company', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('alter', 'VB', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('practices', 'NNS', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/clayton/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE European/JJ)\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  (PERSON Google/NNP)\n",
      "  a/DT\n",
      "  record/NN\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  power/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  mobile/JJ\n",
      "  phone/NN\n",
      "  market/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  the/DT\n",
      "  company/NN\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "ne_tree = nltk.ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(European, Google, $5.1 billion, Wednesday)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'NORP'),\n",
      " ('Google', 'ORG'),\n",
      " ('$5.1 billion', 'MONEY'),\n",
      " ('Wednesday', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "pprint([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'fined',\n",
       "  'lemma': 'fin',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBD',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'authorities',\n",
       "    'lemma': 'authority',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'NNS',\n",
       "    'POS_coarse': 'NOUN',\n",
       "    'arc': 'nsubj',\n",
       "    'modifiers': [{'word': 'European',\n",
       "      'lemma': 'European',\n",
       "      'NE': 'NORP',\n",
       "      'POS_fine': 'JJ',\n",
       "      'POS_coarse': 'ADJ',\n",
       "      'arc': 'amod',\n",
       "      'modifiers': []}]},\n",
       "   {'word': 'Google',\n",
       "    'lemma': 'Google',\n",
       "    'NE': 'ORG',\n",
       "    'POS_fine': 'NNP',\n",
       "    'POS_coarse': 'PROPN',\n",
       "    'arc': 'dative',\n",
       "    'modifiers': []},\n",
       "   {'word': 'record',\n",
       "    'lemma': 'record',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'NN',\n",
       "    'POS_coarse': 'NOUN',\n",
       "    'arc': 'dobj',\n",
       "    'modifiers': [{'word': 'a',\n",
       "      'lemma': 'a',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'DT',\n",
       "      'POS_coarse': 'DET',\n",
       "      'arc': 'det',\n",
       "      'modifiers': []},\n",
       "     {'word': '$ 5.1 billion',\n",
       "      'lemma': '$ 5.1 billion',\n",
       "      'NE': 'MONEY',\n",
       "      'POS_fine': 'CD',\n",
       "      'POS_coarse': 'NUM',\n",
       "      'arc': 'nummod',\n",
       "      'modifiers': []},\n",
       "     {'word': 'on',\n",
       "      'lemma': 'on',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'IN',\n",
       "      'POS_coarse': 'ADP',\n",
       "      'arc': 'prep',\n",
       "      'modifiers': [{'word': 'Wednesday',\n",
       "        'lemma': 'Wednesday',\n",
       "        'NE': 'DATE',\n",
       "        'POS_fine': 'NNP',\n",
       "        'POS_coarse': 'PROPN',\n",
       "        'arc': 'pobj',\n",
       "        'modifiers': []}]},\n",
       "     {'word': 'for',\n",
       "      'lemma': 'for',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'IN',\n",
       "      'POS_coarse': 'ADP',\n",
       "      'arc': 'prep',\n",
       "      'modifiers': [{'word': 'abusing',\n",
       "        'lemma': 'abuse',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'VBG',\n",
       "        'POS_coarse': 'VERB',\n",
       "        'arc': 'pcomp',\n",
       "        'modifiers': [{'word': 'power',\n",
       "          'lemma': 'power',\n",
       "          'NE': '',\n",
       "          'POS_fine': 'NN',\n",
       "          'POS_coarse': 'NOUN',\n",
       "          'arc': 'dobj',\n",
       "          'modifiers': [{'word': 'its',\n",
       "            'lemma': '-PRON-',\n",
       "            'NE': '',\n",
       "            'POS_fine': 'PRP$',\n",
       "            'POS_coarse': 'ADJ',\n",
       "            'arc': 'poss',\n",
       "            'modifiers': []},\n",
       "           {'word': 'in',\n",
       "            'lemma': 'in',\n",
       "            'NE': '',\n",
       "            'POS_fine': 'IN',\n",
       "            'POS_coarse': 'ADP',\n",
       "            'arc': 'prep',\n",
       "            'modifiers': [{'word': 'market',\n",
       "              'lemma': 'market',\n",
       "              'NE': '',\n",
       "              'POS_fine': 'NN',\n",
       "              'POS_coarse': 'NOUN',\n",
       "              'arc': 'pobj',\n",
       "              'modifiers': [{'word': 'the',\n",
       "                'lemma': 'the',\n",
       "                'NE': '',\n",
       "                'POS_fine': 'DT',\n",
       "                'POS_coarse': 'DET',\n",
       "                'arc': 'det',\n",
       "                'modifiers': []},\n",
       "               {'word': 'phone',\n",
       "                'lemma': 'phone',\n",
       "                'NE': '',\n",
       "                'POS_fine': 'NN',\n",
       "                'POS_coarse': 'NOUN',\n",
       "                'arc': 'compound',\n",
       "                'modifiers': [{'word': 'mobile',\n",
       "                  'lemma': 'mobile',\n",
       "                  'NE': '',\n",
       "                  'POS_fine': 'JJ',\n",
       "                  'POS_coarse': 'ADJ',\n",
       "                  'arc': 'amod',\n",
       "                  'modifiers': []}]}]}]}]}]}]}]},\n",
       "   {'word': 'and',\n",
       "    'lemma': 'and',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'CC',\n",
       "    'POS_coarse': 'CCONJ',\n",
       "    'arc': 'cc',\n",
       "    'modifiers': []},\n",
       "   {'word': 'ordered',\n",
       "    'lemma': 'order',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'VBD',\n",
       "    'POS_coarse': 'VERB',\n",
       "    'arc': 'conj',\n",
       "    'modifiers': [{'word': 'company',\n",
       "      'lemma': 'company',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'NN',\n",
       "      'POS_coarse': 'NOUN',\n",
       "      'arc': 'dobj',\n",
       "      'modifiers': [{'word': 'the',\n",
       "        'lemma': 'the',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'DT',\n",
       "        'POS_coarse': 'DET',\n",
       "        'arc': 'det',\n",
       "        'modifiers': []}]},\n",
       "     {'word': 'alter',\n",
       "      'lemma': 'alter',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'VB',\n",
       "      'POS_coarse': 'VERB',\n",
       "      'arc': 'xcomp',\n",
       "      'modifiers': [{'word': 'to',\n",
       "        'lemma': 'to',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'TO',\n",
       "        'POS_coarse': 'PART',\n",
       "        'arc': 'aux',\n",
       "        'modifiers': []},\n",
       "       {'word': 'practices',\n",
       "        'lemma': 'practice',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'NNS',\n",
       "        'POS_coarse': 'NOUN',\n",
       "        'arc': 'dobj',\n",
       "        'modifiers': [{'word': 'its',\n",
       "          'lemma': '-PRON-',\n",
       "          'NE': '',\n",
       "          'POS_fine': 'PRP$',\n",
       "          'POS_coarse': 'ADJ',\n",
       "          'arc': 'poss',\n",
       "          'modifiers': []}]}]}]}]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NORP': 1, 'ORG': 1, 'MONEY': 1, 'DATE': 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [x.label_ for x in doc.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " authorities fined \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " a record \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $5.1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Wednesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " for abusing its power in the mobile phone market and ordered the company to alter its practices</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(ex), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ffafdc155c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/spacy/displacy/__init__.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(docs, style, page, minify, options, manual, port)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mwsgiref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     render(docs, style=style, page=page, minify=minify, options=options,\n\u001b[0;32m---> 62\u001b[0;31m            manual=manual)\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mhttpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0.0.0.0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     prints(\"Using the '{}' visualizer\".format(style),\n",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/spacy/displacy/__init__.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(docs, style, page, minify, jupyter, options, manual)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmanual\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0m_html\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_html\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/spacy/displacy/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmanual\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0m_html\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_html\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/spacy/displacy/__init__.py\u001b[0m in \u001b[0;36mparse_deps\u001b[0;34m(orig_doc, options)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGenerated\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0mparse\u001b[0m \u001b[0mkeyed\u001b[0m \u001b[0mby\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0muser_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.to_bytes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(getters, exclude)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mserialized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsgpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bin_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_py3/lib/python3.6/site-packages/msgpack_numpy.py\u001b[0m in \u001b[0;36mpackb\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style='dep') \n",
    "\n",
    "# error - known issue: https://github.com/explosion/spaCy/issues/2868 - incompatible msgpack version, it seems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real articles\n",
    "\n",
    "Test NER against 2009 News Crawl data provided at [kylebgorman/LING83600-mp00.md](https://gist.github.com/kylebgorman/3e28fc834962017c9ac01f7434485519)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
